# ==============================================================================
# PHARMACY AGENT - ENVIRONMENT CONFIGURATION
# ==============================================================================
# Copy this file to .env and fill in your values
# See PERFORMANCE_GUIDE.md for detailed optimization tips

# ==============================================================================
# OPENAI API CONFIGURATION
# ==============================================================================
OPENAI_API_KEY=your-openai-api-key-here

# ==============================================================================
# MODEL SELECTION
# ==============================================================================
# LLM Model - Choose based on your speed/accuracy requirements:
#   - gpt-3.5-turbo-0125  : Fastest, cheapest (good for testing)
#   - gpt-4o-mini         : Fast + accurate (RECOMMENDED for production)
#   - gpt-4o              : Most accurate, slower, expensive
LLM_MODEL=gpt-4o-mini

# Embedding Model - For document similarity search:
#   - text-embedding-3-small : Fast, 1536 dimensions (RECOMMENDED)
#   - text-embedding-3-large : More accurate, 3072 dimensions (slower, costlier)
EMBEDDING_MODEL=text-embedding-3-small

# ==============================================================================
# LLM GENERATION PARAMETERS
# ==============================================================================
# Maximum tokens in LLM response (lower = faster, cheaper)
# Range: 1024-8192, Recommended: 4096
MAX_TOKENS=4096

# Temperature (0.0-2.0) - Lower = more deterministic & faster
# 0.0   = Fully deterministic (fastest)
# 0.1   = Very low randomness (RECOMMENDED)
# 0.5   = Balanced creativity
# 1.0+  = More creative (slower)
TEMPERATURE=0.1

# ==============================================================================
# DOCUMENT CHUNKING CONFIGURATION
# ==============================================================================
# Chunk Size in characters (not tokens)
# ~512 tokens = 2048 chars, ~1024 tokens = 4096 chars
# Larger chunks = more context but fewer chunks retrieved
CHUNK_SIZE=2048

# Chunk Overlap in characters
# Prevents information loss at chunk boundaries
# Typical: 10-20% of CHUNK_SIZE
CHUNK_OVERLAP=256

# Chunking Strategy:
#   - semantic  : Split by meaning (RECOMMENDED, best quality)
#   - fixed     : Fixed-size chunks (faster processing)
#   - hybrid    : Combination approach
CHUNKING_STRATEGY=semantic

# Semantic chunking parameters (only used if CHUNKING_STRATEGY=semantic)
MIN_CHUNK_SIZE=512
MAX_CHUNK_SIZE=4096
PRESERVE_PARAGRAPHS=true

# ==============================================================================
# RETRIEVAL SETTINGS
# ==============================================================================
# Number of SUT chunks to retrieve per drug
# Lower = faster LLM processing, higher = more context
# Recommendations:
#   3  = Fast (may miss some context)
#   5  = Balanced (RECOMMENDED)
#   10 = Comprehensive (slower)
TOP_K_CHUNKS=5

# ==============================================================================
# PERFORMANCE OPTIMIZATION FLAGS
# ==============================================================================
# Enable response streaming (future feature - improves perceived performance)
ENABLE_STREAMING=true

# Use parallel embeddings (batch OpenAI API calls)
# Should always be true unless debugging
PARALLEL_EMBEDDINGS=true

# Cache query embeddings to disk (huge speed improvement for repeat queries)
# Should always be true in production
CACHE_EMBEDDINGS=true

# ==============================================================================
# LANGUAGE SETTINGS
# ==============================================================================
# Output language for LLM responses
OUTPUT_LANGUAGE=turkish

# ==============================================================================
# FILE PATHS (usually don't need to change)
# ==============================================================================
# FAISS vector store configuration
EMBEDDING_DIMENSION=1536
FAISS_INDEX_PATH=data/faiss_index
FAISS_METADATA_PATH=data/faiss_metadata.json

# SUT PDF and sample reports
SUT_PDF_PATH=data/9.5.17229.pdf
SAMPLE_REPORTS_DIR=data/sample_reports

# ==============================================================================
# PERFORMANCE PRESETS
# ==============================================================================
# Uncomment one of these presets to quickly configure performance

# --- PRESET: MAXIMUM SPEED (may reduce accuracy) ---
# LLM_MODEL=gpt-3.5-turbo-0125
# TOP_K_CHUNKS=3
# MAX_TOKENS=2048
# TEMPERATURE=0.0
# CHUNK_SIZE=1024
# CHUNK_OVERLAP=128

# --- PRESET: BALANCED (RECOMMENDED) ---
# LLM_MODEL=gpt-4o-mini
# TOP_K_CHUNKS=5
# MAX_TOKENS=4096
# TEMPERATURE=0.1
# CHUNK_SIZE=2048
# CHUNK_OVERLAP=256

# --- PRESET: MAXIMUM ACCURACY (slower) ---
# LLM_MODEL=gpt-4o
# TOP_K_CHUNKS=10
# MAX_TOKENS=8192
# TEMPERATURE=0.2
# CHUNK_SIZE=4096
# CHUNK_OVERLAP=512
# EMBEDDING_MODEL=text-embedding-3-large

# ==============================================================================
# DEBUGGING & LOGGING
# ==============================================================================
# Set to DEBUG for verbose logging (useful for performance analysis)
# LOG_LEVEL=INFO
