# Pharmacy Agent - SUT Compliance Checker

## Sistem Mimarisi ve Proje DokÃ¼mantasyonu

---

## 1. PROJE Ã–ZET

### 1.1 Problem TanÄ±mÄ±

TÃ¼rk saÄŸlÄ±k sistemi kapsamÄ±nda, eczacÄ±lar hastalardan gelen reÃ§etelerdeki ilaÃ§larÄ±n SGK (Sosyal GÃ¼venlik Kurumu) tarafÄ±ndan karÅŸÄ±lanÄ±p karÅŸÄ±lanmayacaÄŸÄ±nÄ± manuel olarak SUT (SaÄŸlÄ±k Uygulama TebliÄŸi) dokÃ¼manÄ±nÄ± kontrol ederek belirlemek zorundadÄ±r. Bu 15,000+ satÄ±rlÄ±k dokÃ¼manda arama yapmak Ã§ok zaman alÄ±cÄ±dÄ±r.

### 1.2 Ã‡Ã¶zÃ¼m

AI destekli bir ajan sistemi oluÅŸturulacak:

- **Girdi**: HastanÄ±n reÃ§ete raporu (metin formatÄ±nda Ctrl+C/Ctrl+V ile)
- **Ä°ÅŸlem**: RAG (Retrieval Augmented Generation) ile SUT dokÃ¼manÄ±nda ilgili kurallarÄ± bulma
- **Ã‡Ä±ktÄ±**: Her ilaÃ§ iÃ§in detaylÄ± uygunluk analizi (TÃ¼rkÃ§e)

### 1.3 Teknoloji Stack

- **LLM**: Google Gemini 2.0 Flash (via OpenRouter)
- **Vector DB**: FAISS (Local, Fast, Accurate)
- **Framework**: Python
- **Interface**: CLI (MVP)

---

## 2. SÄ°STEM MÄ°MARÄ°SÄ°

```mermaid
graph TB
    A[EczacÄ±/Pharmacist] -->|Rapor metnini yapÄ±ÅŸtÄ±rÄ±r| B[CLI Interface]
    B --> C[Input Parser]
    C --> D[Report Analyzer]
    D --> E{Rapor Ä°Ã§eriÄŸi Ã‡Ä±karma}
    E -->|Ä°laÃ§ Listesi| F[Drug Extractor]
    E -->|TanÄ± KodlarÄ±| G[Diagnosis Extractor]
    E -->|Hasta Bilgileri| H[Patient Info Extractor]

    F --> I[Query Builder]
    G --> I
    H --> I

    I --> J[RAG Retrieval Engine]
    J --> K[FAISS Vector Store<br/>SUT Chunks]
    K -->|Ä°lgili SUT bÃ¶lÃ¼mleri| J

    J --> L[LLM Processor<br/>Google Gemini 2.0]
    L --> M[Eligibility Analyzer]
    M --> N[Response Formatter]
    N --> O[CLI Output<br/>TÃ¼rkÃ§e SonuÃ§lar]
    O --> A

    style K fill:#e1f5ff
    style L fill:#ffe1e1
    style O fill:#e1ffe1
```

---

```

---

## 3. DETAYLI BILEÅEN TASARIMI

### 3.1 Input Parser (Girdi Ä°ÅŸleyici)

**GÃ¶rev**: Ham rapor metnini iÅŸlenebilir yapÄ±ya dÃ¶nÃ¼ÅŸtÃ¼rme

**Fonksiyonlar**:
```python
class InputParser:
    def parse_report(self, raw_text: str) -> ParsedReport
    def validate_input(self, raw_text: str) -> bool
    def clean_text(self, text: str) -> str
```

**Ã‡Ä±karÄ±lacak Bilgiler**:



### 3.2 Report Analyzer (Rapor Analiz Motoru)

**Alt ModÃ¼ller**:

#### 3.2.1 Drug Extractor

```python
class DrugExtractor:
    def extract_drugs(self, report: ParsedReport) -> List[Drug]

@dataclass
class Drug:
    kod: str                    # SGKF07
    etkin_madde: str           # EZETIMIB
    form: str                  # AÄŸÄ±zdan katÄ±
    tedavi_sema: str          # GÃ¼nde 1 x 1.0 Adet
    miktar: int               # 1
    eklenme_zamani: date      # 26/12/2024
```

#### 3.2.2 Diagnosis Extractor

```python
class DiagnosisExtractor:
    def extract_diagnoses(self, report: ParsedReport) -> List[Diagnosis]

@dataclass
class Diagnosis:
    icd10_code: str           # I25.1
    tanim: str                # Aterosklerotik Kalp HastalÄ±ÄŸÄ±
    baslangic: date
    bitis: date
```

#### 3.2.3 Patient Info Extractor

```python
class PatientInfoExtractor:
    def extract_patient_info(self, report: ParsedReport) -> PatientInfo

@dataclass
class PatientInfo:
    cinsiyet: str
    dogum_tarihi: date
    yas: int
    # Privacy: TC kimlik saklanmayacak
```

---

### 3.3 SUT Document Processing (DokÃ¼man Ä°ÅŸleme)

**Chunking Stratejisi**: SUT dokÃ¼manÄ± anlamlÄ± bÃ¶lÃ¼mlere ayrÄ±lacak

```python
class SUTDocumentProcessor:
    def load_pdf(self, filepath: str) -> str
    def chunk_document(self, text: str) -> List[Chunk]
    def create_embeddings(self, chunks: List[Chunk]) -> List[Embedding]

@dataclass
class Chunk:
    chunk_id: str
    content: str
    metadata: ChunkMetadata
    start_line: int
    end_line: int

@dataclass
class ChunkMetadata:
    section: str              # "4.2.28" (madde numarasÄ±)
    topic: str                # "Lipid dÃ¼ÅŸÃ¼rÃ¼cÃ¼ ilaÃ§lar"
    etkin_madde: List[str]    # ["ezetimib", "statin"]
    keywords: List[str]       # Ã¶nemli terimler
    drug_related: bool
    has_conditions: bool
```

**Chunking KurallarÄ±**:

1. **Madde bazlÄ±**: Her madde (4.2.1, 4.2.2, vb.) ayrÄ± chunk
2. **Overlap**: 100-200 karakter overlap (baÄŸlam korunmasÄ± iÃ§in)
3. **Chunk Size**: 500-1000 token (Google Gemini iÃ§in optimal)
4. **Metadata Enrichment**: Her chunk'a ilgili ilaÃ§ isimleri, tanÄ± kodlarÄ± eklenir

**Ã–rnek Chunk**:

```text
Content: "4.2.28.C â€“ Ezetimib iÃ§eren mono/kombine Ã¼rÃ¼nler...
En az 6 ay boyunca statinlerle tedavi edilmiÅŸ olmasÄ±na raÄŸmen..."

Metadata:
  section: "4.2.28.C"
  topic: "Ezetimib kullanÄ±m ilkeleri"
  etkin_madde: ["ezetimib", "statin"]
  keywords: ["LDL", "kardiyoloji", "uzman hekim raporu"]
  has_conditions: true
  start_line: 12528
  end_line: 12550
```

---

### 3.4 RAG Retrieval Engine

**FAISS Index YapÄ±sÄ±**:

```python
# Index Configuration
{
    "dimension": 1536,  # OpenAI text-embedding-3-small
    "index_type": "IndexFlatL2",  # Exact search for accuracy
    "metric": "L2",  # L2 distance (converted to similarity)
    "metadata": {
        "stored_fields": [
            "section",
            "etkin_madde",
            "drug_related",
            "has_conditions",
            "content"
        ]
    }
}
```

**Retrieval Stratejisi**:

```python
class RAGRetriever:
    def retrieve_relevant_chunks(
        self,
        query: str,
        drugs: List[Drug],
        filters: Dict
    ) -> List[RetrievedChunk]:
        """
        1. Her ilaÃ§ iÃ§in ayrÄ± sorgu oluÅŸtur
        2. Hybrid search: semantic + keyword filtering
        3. Top-k chunks getir (k=5-10)
        4. Re-ranking uygula (relevance score)
        """
        pass
```

**Query Construction**:

```python
# Ã–rnek: Ezetimib iÃ§in sorgu
query = f"""
Ä°laÃ§: {drug.etkin_madde}
TanÄ±: {diagnosis.tanim} ({diagnosis.icd10_code})
BranÅŸ: {doctor.brans}
Hasta YaÅŸÄ±: {patient.yas}
"""

# Metadata Filters
filters = {
    "etkin_madde": {"$in": ["ezetimib", "EZETIMIB"]},
    "drug_related": True
}
```

---

### 3.5 LLM Processor (OpenAI Integration)

**Prompt Engineering**:

```python
SYSTEM_PROMPT = """
Sen bir TÃ¼rk saÄŸlÄ±k sistemi uzmanÄ±sÄ±n. SUT (SaÄŸlÄ±k Uygulama TebliÄŸi) dokÃ¼mantasyonuna
gÃ¶re ilaÃ§larÄ±n SGK kapsamÄ±nda olup olmadÄ±ÄŸÄ±nÄ± deÄŸerlendiriyorsun.

GÃ¶revin:
1. Verilen hasta raporu ve ilgili SUT bÃ¶lÃ¼mlerini analiz et
2. Her ilaÃ§ iÃ§in uygunluk kriterlerini kontrol et
3. DetaylÄ± ve anlaÅŸÄ±lÄ±r TÃ¼rkÃ§e aÃ§Ä±klama yap

Ã‡Ä±ktÄ± formatÄ±:
- Emoji kullan (âœ… uygun, âŒ uygun deÄŸil, âš ï¸ koÅŸullu)
- SUT madde numaralarÄ±nÄ± belirt
- ÅartlarÄ± aÃ§Ä±kÃ§a listele
"""

USER_PROMPT_TEMPLATE = """
Hasta Raporu:
{report_content}

Ä°laÃ§: {drug_name}
TanÄ±: {diagnosis}

Ä°lgili SUT BÃ¶lÃ¼mleri:
{retrieved_chunks}

LÃ¼tfen bu ilacÄ±n SGK kapsamÄ±nda karÅŸÄ±lanÄ±p karÅŸÄ±lanmayacaÄŸÄ±nÄ± deÄŸerlendir.
"""
```

---

### 3.6 Eligibility Analyzer (Uygunluk DeÄŸerlendirici)

**DeÄŸerlendirme MantÄ±ÄŸÄ±**:

```python
@dataclass
class EligibilityResult:
    drug_name: str
    status: Literal["ELIGIBLE", "NOT_ELIGIBLE", "CONDITIONAL"]
    confidence: float  # 0.0 - 1.0
    sut_reference: str  # "4.2.28.C (satÄ±r 12528-12550)"
    conditions: List[Condition]
    explanation: str  # TÃ¼rkÃ§e aÃ§Ä±klama
    warnings: List[str]

@dataclass
class Condition:
    description: str
    is_met: Optional[bool]  # True/False/None (belirlenemedi)
    required_info: str  # Eksik bilgi varsa
```

**Ã–rnek Ã‡Ä±ktÄ±**:
```text
âœ… EZETIMIB - SGK KAPSAMINDA

SUT Referans: 4.2.28.C (satÄ±r 12528-12550)

KoÅŸullar:
âœ… En az 6 ay statin tedavisi gerekli
   â†’ Raporda belirtilmiÅŸ: "Monoterapi ile kanbasÄ±ncÄ± yeterli oranda kontrol altÄ±na alÄ±namÄ±ÅŸtÄ±r"

âš ï¸ LDL dÃ¼zeyi 100 mg/dL Ã¼zerinde olmalÄ±
   â†’ Raporda LDL deÄŸeri bulunamadÄ± - eczacÄ± doktora danÄ±ÅŸmalÄ±

âœ… Kardiyoloji/iÃ§ hastalÄ±klarÄ± uzman raporu gerekli
   â†’ Rapor kardiyoloji uzmanÄ± tarafÄ±ndan dÃ¼zenlenmiÅŸ (Dr. BÃ¼lent Uzunlar)

Ã–zet: Ä°laÃ§ SGK kapsamÄ±nda ancak LDL test sonucu doÄŸrulanmalÄ±.
```

---

## 4. VERÄ° AKIÅI

### 4.1 Ä°ÅŸlem AdÄ±mlarÄ±

```mermaid
sequenceDiagram
    participant E as EczacÄ±
    participant C as CLI
    participant P as Parser
    participant R as RAG Engine
    participant V as Pinecone
    participant L as LLM (Gemini 2.0)
    participant O as Output Formatter

    E->>C: Rapor metnini yapÄ±ÅŸtÄ±r
    C->>P: Ham metin
    P->>P: Rapor parse et
    P->>R: ParsedReport (ilaÃ§lar, tanÄ±lar)

    loop Her ilaÃ§ iÃ§in
        R->>V: VektÃ¶r sorgusu + metadata filter
        V->>R: Top-k ilgili SUT chunks
        R->>L: Prompt (rapor + chunks)
        L->>R: Uygunluk analizi
        R->>O: EligibilityResult
    end

    O->>C: FormatlanmÄ±ÅŸ TÃ¼rkÃ§e sonuÃ§
    C->>E: Ekranda gÃ¶ster
```

### 4.2 Ã–rnek Veri DÃ¶nÃ¼ÅŸÃ¼mÃ¼

**1. Raw Input** (EczacÄ± yapÄ±ÅŸtÄ±rÄ±r):
```text
Rapor No: 277870
Hasta: ALÄ° KAYA
TanÄ±: I25.1 Aterosklerotik Kalp HastalÄ±ÄŸÄ±

Ä°laÃ§lar:
SGKF07 EZETIMIB - GÃ¼nde 1x1 Adet
SGKF05 METOPROLOL - GÃ¼nde 1x1 Adet
```

**2. Parsed Structure**:
```json
{
  "report_id": "277870",
  "date": "26/12/2024",
  "hospital_code": "12415060",
  "doctor": {
    "name": "BÃœLENT UZUNLAR",
    "specialty": "Kardiyoloji",
    "diploma": "89841"
  },
  "diagnoses": [
    {
      "code": "I25.1",
      "name": "Aterosklerotik Kalp HastalÄ±ÄŸÄ±",
      "start_date": "26/12/2024"
    }
  ],
  "drugs": [
    {
      "code": "SGKF07",
      "name": "EZETIMIB",
      "form": "AÄŸÄ±zdan katÄ±",
      "dosage": "GÃ¼nde 1 x 1.0 Adet"
    }
  ]
}
```

**3. Vector Query** (Her ilaÃ§ iÃ§in):
```python
{
  "query_embedding": [0.123, -0.456, ...],  # embedding of query
  "filters": {
    "drug_related": True
  },
  "top_k": 10
}
```

**4. Retrieved Chunks** (FAISS'ten):
```python
[
  {
    "chunk_id": "sut_4_2_28_c",
    "content": "4.2.28.C â€“ Ezetimib iÃ§eren mono/kombine Ã¼rÃ¼nler...",
    "score": 0.89,
    "metadata": {
      "section": "4.2.28.C",
      "start_line": 12528,
      "end_line": 12550
    }
  }
]
```

**5. LLM Output**:
```json
{
  "drug_name": "EZETIMIB",
  "status": "CONDITIONAL",
  "confidence": 0.85,
  "sut_reference": "4.2.28.C (satÄ±r 12528-12550)",
  "conditions": [
    {
      "description": "En az 6 ay statin tedavisi almÄ±ÅŸ olmalÄ±",
      "is_met": null,
      "required_info": "Hasta geÃ§miÅŸinde statin kullanÄ±mÄ± bilgisi"
    },
    {
      "description": "LDL dÃ¼zeyi 100 mg/dL Ã¼zerinde olmalÄ±",
      "is_met": null,
      "required_info": "LDL test sonucu"
    }
  ],
  "explanation": "Ezetimib SGK kapsamÄ±nda ancak..."
}
```

---

## 5. TEKNIK DETAYLAR

### 5.1 FAISS Vector Database Setup

```python
from rag.faiss_store import FAISSVectorStore
from openai import OpenAI

# Initialize
vector_store = FAISSVectorStore()
client = OpenAI(api_key=OPENAI_API_KEY)

# Create index
vector_store.create_index(dimension=1536)

# Index SUT document
def index_sut_document(pdf_path: str):
    # 1. PDF â†’ text
    text = extract_text_from_pdf(pdf_path)

    # 2. Chunk creation
    chunks = chunk_by_sections(text)

    # 3. Create embeddings
    embeddings_data = []
    for chunk in chunks:
        embedding = client.embeddings.create(
            model="text-embedding-3-small",
            input=chunk.content,
            encoding_format="float"
        )

        # 4. Prepare for FAISS
        embeddings_data.append({
            "id": chunk.chunk_id,
            "values": embedding.data[0].embedding,
            "metadata": {
                "content": chunk.content,
                "section": chunk.metadata.section,
                "etkin_madde": chunk.metadata.etkin_madde,
                "start_line": chunk.start_line,
                "end_line": chunk.end_line
            }
        })

    # 5. Add to FAISS and save
    vector_store.add_embeddings(embeddings_data)
    vector_store.save()
```

### 5.2 RAG Query Pipeline

```python
class RAGQueryPipeline:
    def __init__(self, vector_store: FAISSVectorStore, openai_client):
        self.vector_store = vector_store
        self.client = openai_client

    def query(self, drug: Drug, diagnosis: Diagnosis, patient: PatientInfo):
        # 1. Construct semantic query
        query_text = self._build_query_text(drug, diagnosis, patient)

        # 2. Get embedding
        query_embedding = self.client.embeddings.create(
            model="text-embedding-3-small",
            input=query_text
        ).data[0].embedding

        # 3. Search with metadata filters
        results = self.vector_store.search(
            query_embedding=query_embedding,
            top_k=10,
            filters={
                "drug_related": True
            }
        )

        # 4. Filter by drug name (manual filtering)
        drug_matches = [
            r for r in results
            if any(drug.etkin_madde.lower() in em.lower()
                   for em in r['metadata'].get('etkin_madde', []))
        ]

        # 5. Re-rank by relevance
        ranked_chunks = self._rerank(drug_matches if drug_matches else results)

        return ranked_chunks[:5]  # Top 5
```

### 5.3 LLM Eligibility Check

```python
class EligibilityChecker:
    def check_eligibility(
        self,
        drug: Drug,
        diagnosis: Diagnosis,
        patient: PatientInfo,
        sut_chunks: List[Chunk]
    ) -> EligibilityResult:

        # Construct prompt
        prompt = self._build_prompt(drug, diagnosis, patient, sut_chunks)

        # Call Google Gemini
        response = self.client.chat.completions.create(
            model="google/gemini-2.0-flash-001",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"}
        )

        # Parse response
        result = json.loads(response.choices[0].message.content)

        return EligibilityResult(**result)
```

---

## 6. PROJE YAPISI

```text
pharmacy-agent/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ 9.5.17229.pdf          # SUT document
â”‚   â””â”€â”€ sample_reports/         # Test iÃ§in Ã¶rnek raporlar
â”‚       â””â”€â”€ sample_1.txt
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ settings.py         # API keys, config
â”‚   â”‚
â”‚   â”œâ”€â”€ parsers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ input_parser.py     # Raw text â†’ ParsedReport
â”‚   â”‚   â”œâ”€â”€ drug_extractor.py
â”‚   â”‚   â”œâ”€â”€ diagnosis_extractor.py
â”‚   â”‚   â””â”€â”€ patient_extractor.py
â”‚   â”‚
â”‚   â”œâ”€â”€ document_processing/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ pdf_loader.py       # PDF â†’ text
â”‚   â”‚   â”œâ”€â”€ chunker.py          # Text â†’ chunks
â”‚   â”‚   â”œâ”€â”€ metadata_enricher.py
â”‚   â”‚   â””â”€â”€ embeddings.py       # Chunks â†’ vectors
â”‚   â”‚
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ vector_store.py     # Pinecone operations
â”‚   â”‚   â”œâ”€â”€ retriever.py        # Query + retrieve
â”‚   â”‚   â””â”€â”€ reranker.py         # Result re-ranking
â”‚   â”‚
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ openai_client.py    # OpenAI API wrapper
â”‚   â”‚   â”œâ”€â”€ prompts.py          # Prompt templates
â”‚   â”‚   â””â”€â”€ eligibility_checker.py
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ report.py           # Data classes
â”‚   â”‚   â”œâ”€â”€ drug.py
â”‚   â”‚   â”œâ”€â”€ diagnosis.py
â”‚   â”‚   â””â”€â”€ eligibility.py
â”‚   â”‚
â”‚   â””â”€â”€ cli/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ main.py             # CLI interface
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup_faiss.py          # One-time: index SUT
â”‚   â”œâ”€â”€ test_extraction.py      # Test parsers
â”‚   â””â”€â”€ evaluate_accuracy.py    # Accuracy testing
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_parsers.py
    â”œâ”€â”€ test_rag.py
    â””â”€â”€ test_eligibility.py
```

---

## 7. IMPLEMENTATION PHASES

### Phase 1: Setup & Document Processing (Week 1)

- [x] Setup project structure
- [x] Install dependencies (openai, faiss-cpu, PyPDF2)
- [x] Extract text from 9.5.17229.pdf
- [x] Implement chunking strategy
- [x] Create embeddings
- [x] Index to FAISS

### Phase 2: Report Parsing (Week 1-2)
- [ ] Build InputParser
- [ ] Extract drugs from report
- [ ] Extract diagnoses (ICD-10 codes)
- [ ] Extract patient & doctor info
- [ ] Unit tests for parsers

### Phase 3: RAG System (Week 2)
- [ ] Implement RAGRetriever
- [ ] Query construction logic
- [ ] Metadata filtering
- [ ] Test retrieval accuracy

### Phase 4: LLM Integration (Week 2-3)
- [ ] OpenAI API integration
- [ ] Prompt engineering
- [ ] EligibilityChecker implementation
- [ ] JSON response parsing

### Phase 5: CLI Interface (Week 3)
- [ ] Build CLI with input/output
- [ ] Format Turkish output
- [ ] Add colored output (rich library)
- [ ] User-friendly error messages

### Phase 6: Testing & Validation (Week 3-4)
- [ ] Test with real patient reports
- [ ] Validate against manual SUT checks
- [ ] Measure accuracy
- [ ] Refine prompts

---

## 8. KEY DEPENDENCIES

```txt
# requirements.txt
openai>=1.0.0
faiss-cpu>=1.7.4
numpy>=1.24.0
python-dotenv>=1.0.0
PyPDF2>=3.0.0
pydantic>=2.0.0
rich>=13.0.0          # CLI formatting
langchain>=0.1.0      # Optional: for advanced RAG
tiktoken>=0.5.0       # Token counting
```

---

## 9. CONFIGURATION

```python
# .env.example
OPENAI_API_KEY=sk-...

# Model settings
EMBEDDING_MODEL=text-embedding-3-small
LLM_MODEL=google/gemini-2.0-flash-001
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
TOP_K_CHUNKS=5

# Language
OUTPUT_LANGUAGE=turkish
```

---

## 10. Ã–RNEK KULLANIM (CLI)

```bash
$ python -m src.cli.main

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          ECZANE SUT UYGUNLUK KONTROLÃœ                   â•‘
â•‘          Pharmacy SGK Eligibility Checker                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Hasta raporunu yapÄ±ÅŸtÄ±rÄ±n (Ctrl+V) ve Enter'a basÄ±n:
[Ctrl+D ile bitirin]

> [EczacÄ± raporu yapÄ±ÅŸtÄ±rÄ±r]

Analiz ediliyor... â³

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ RAPOR ANALÄ°Z SONUÃ‡LARI                                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ Rapor Bilgileri:
  â€¢ Rapor No: 277870
  â€¢ Tarih: 26/12/2024
  â€¢ Doktor: Dr. BÃ¼lent Uzunlar (Kardiyoloji)
  â€¢ TanÄ±: I25.1 - Aterosklerotik Kalp HastalÄ±ÄŸÄ±

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ’Š Ä°LAÃ‡ ANALÄ°ZÄ° (5 ilaÃ§ bulundu)

1ï¸âƒ£  KLOPIDOGREL HIDROJEN SULFAT
    âœ… SGK KAPSAMINDA KARÅILANIR

    ğŸ“– SUT Referans: Madde 4.2.15.A (satÄ±r 11177-11191)

    âœ… KoÅŸullar SaÄŸlanÄ±yor:
       â€¢ Koroner arter hastalÄ±ÄŸÄ± mevcut
       â€¢ Kardiyoloji uzmanÄ± raporu var
       â€¢ KullanÄ±m sÃ¼resi belirtilmiÅŸ (12 ay)

    â„¹ï¸  Not: Tedavi sÃ¼resi 12 ay geÃ§memeli

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

2ï¸âƒ£  METOPROLOL
    âœ… SGK KAPSAMINDA KARÅILANIR

    ğŸ“– Rapor ÅŸartÄ± yok, tÃ¼m hekimler reÃ§ete edebilir

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

3ï¸âƒ£  EZETIMIB
    âš ï¸  KOÅULLU - EK BÄ°LGÄ° GEREKÄ°YOR

    ğŸ“– SUT Referans: Madde 4.2.28.C (satÄ±r 12528-12550)

    âœ… SaÄŸlanan koÅŸullar:
       â€¢ Kardiyoloji uzman raporu mevcut

    âš ï¸  Eksik bilgiler:
       â€¢ LDL dÃ¼zeyi 100 mg/dL Ã¼zerinde olmalÄ±
         â†’ Raporda LDL test sonucu yok
       â€¢ En az 6 ay statin tedavisi gerekli
         â†’ Raporda statin kullanÄ±m geÃ§miÅŸi belirtilmemiÅŸ

    ğŸ’¡ Ã–neri: HastanÄ±n LDL test sonucunu ve statin
       tedavi geÃ§miÅŸini doktordan talep edin

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Raporu PDF olarak kaydet? (e/h): _
```

---

## 11. ACCURACY & PERFORMANCE

### 11.1 Accuracy Metrics
- **Target Accuracy**: >95% (kritik saÄŸlÄ±k uygulamasÄ±)
- **Measurement**: Manuel SUT kontrolÃ¼ ile karÅŸÄ±laÅŸtÄ±rma
- **Edge Cases**: Belirsiz durumlar iÃ§in "DOKTORA DANIÅIN" Ã¶nerisi

### 11.2 Performance Targets
- **Response Time**: <10 saniye (5 ilaÃ§ iÃ§in)
- **Cost per Query**: ~$0.005-0.01 (GPT-5-mini + embedding)
- **Throughput**: 100+ sorgu/saat

### 11.3 Error Handling
```python
class SUTCheckerError(Exception):
    """Base exception"""

class ReportParsingError(SUTCheckerError):
    """Rapor parse edilemedi"""

class DrugNotFoundError(SUTCheckerError):
    """Ä°laÃ§ SUT'ta bulunamadÄ±"""

class FAISSIndexError(SUTCheckerError):
    """FAISS index hatasÄ±"""
```

---

## 12. GÃœVENLÄ°K & PRÄ°VACY

### 12.1 Data Privacy
- âœ… **TC Kimlik numaralarÄ±** saklanmaz
- âœ… **Hasta isimleri** loglarda yer almaz
- âœ… **API calls** encryption ile (HTTPS)
- âœ… **Local processing** Ã¶ncelikli

### 12.2 Data Retention
- Sorgu geÃ§miÅŸi saklanmaz (stateless)
- Vector DB sadece SUT dokÃ¼manÄ± iÃ§erir
- Log files hasta bilgisi iÃ§ermez

---

## 13. FUTURE ENHANCEMENTS

### Phase 2 (Web Interface)
- Flask/FastAPI backend
- React frontend
- File upload for report images (OCR)
- Multi-user support

### Phase 3 (Advanced Features)
- PDF rapor yÃ¼kleme (OCR ile)
- Tarihsel analiz (ilaÃ§ uygunluk deÄŸiÅŸimleri)
- Alternatif ilaÃ§ Ã¶nerileri
- SUT gÃ¼ncellemeleri otomatik takip

### Phase 4 (Enterprise)
- Multi-eczane deployment
- Analytics dashboard
- Admin panel (SUT gÃ¼ncelleme)
- Mobile app

---

## 14. TESTING STRATEGY

### 14.1 Unit Tests
```python
def test_drug_extraction():
    report = """
    SGKF07 EZETIMIB AÄŸÄ±zdan katÄ± GÃ¼nde 1 x 1.0
    """
    drugs = DrugExtractor().extract_drugs(report)
    assert drugs[0].etkin_madde == "EZETIMIB"

def test_sut_retrieval():
    query = "ezetimib kardiyoloji raporu"
    chunks = retriever.retrieve(query, top_k=5)
    assert "4.2.28" in chunks[0].metadata.section
```

### 14.2 Integration Tests
```python
def test_end_to_end():
    # GerÃ§ek rapor + SUT
    report = load_sample_report("sample_1.txt")
    results = sut_checker.check_report(report)

    # DoÄŸrulama
    assert results[0].drug_name == "EZETIMIB"
    assert results[0].status in ["ELIGIBLE", "NOT_ELIGIBLE", "CONDITIONAL"]
```

### 14.3 Accuracy Validation
- 50+ gerÃ§ek hasta raporu ile test
- Deneyimli eczacÄ± ile karÅŸÄ±laÅŸtÄ±rma
- False positive/negative oranÄ± <5%

---

## 15. DEPLOYMENT

### MVP Deployment
```bash
# Local CLI
git clone <repo>
cd pharmacy-agent
pip install -r requirements.txt
cp .env.example .env
# Edit .env with API keys

# Index SUT document (one-time)
python scripts/setup_faiss.py

# Run CLI
python -m src.cli.main
```

### Production Considerations
- Docker containerization
- API rate limiting
- Caching frequent queries
- Monitoring & logging (Sentry)

---

## 16. COST ESTIMATION

### Per Query (5 ilaÃ§):
- **Embeddings**: 5 queries Ã— $0.0001 = $0.0005
- **FAISS**: $0 (local, free!)
- **GPT-5-mini**: ~2000 tokens Ã— $0.0025/1K = $0.005
- **Total**: ~$0.02 per report

### Monthly (1000 rapor):
- **Total Cost**: $20-30 (only OpenAI, FAISS is free!)
- **Very affordable** for single pharmacy
- **FAISS saves**: ~$100-200/month vs cloud vector DBs

---

## 17. RISKS & MITIGATIONS

| Risk | Impact | Mitigation |
|------|--------|------------|
| LLM hallucination (yanlÄ±ÅŸ bilgi) | HIGH | Confidence score + "Doktora danÄ±ÅŸ" fallback |
| SUT format deÄŸiÅŸimi | MEDIUM | Modular chunking + easy re-indexing |
| API downtime | MEDIUM | Graceful error handling + retry logic |
| Privacy breach | HIGH | No PII storage + encryption |
| Slow response | LOW | Caching + optimized prompts |

---

## 18. SUCCESS METRICS

### MVP Success Criteria:
- âœ… 10 test raporunda >90% accuracy
- âœ… <10 saniye response time
- âœ… TÃ¼rkÃ§e output quality (readable)
- âœ… Zero false negatives (critical drugs)

### Production Ready:
- âœ… 100+ test raporunda >95% accuracy
- âœ… Web interface deployed
- âœ… 5+ eczane kullanÄ±mÄ±nda
- âœ… Documented API

---

## 19. NEXT STEPS

### Immediate (This Week)

1. âœ… Requirements gathering - DONE
2. âœ… Architecture design - IN PROGRESS
3. â³ Get approval on architecture
4. â³ Setup development environment

### Week 1

- Implement PDF processing
- Build chunking logic
- Index to Pinecone
- Test retrieval

### Week 2

- Build parsers
- Integrate OpenAI
- End-to-end testing
- CLI interface

---

## 20. SORULAR VE KARARLAR

### AÃ§Ä±k Sorular

1. â“ SUT dokÃ¼mantasyonu ne sÄ±klÄ±kla gÃ¼ncellenir?
2. â“ KaÃ§ eczacÄ± kullanacak (multi-user gerekli mi)?
3. â“ ReÃ§ete gÃ¶rÃ¼ntÃ¼sÃ¼ (foto) yÃ¼kleme lazÄ±m mÄ± (OCR)?
4. â“ SonuÃ§larÄ± PDF'e aktarma Ã¶zelliÄŸi?

### Teknik Kararlar

- âœ… OpenAI (GPT-5-mini) kullan - En iyi TÃ¼rkÃ§e desteÄŸi
- âœ… Pinecone - Managed, kolay setup
- âœ… CLI MVP - HÄ±zlÄ± test iÃ§in
- âœ… Chunk size: 1000 token - Optimal balance

---

## CONTACT & SUPPORT

**Developer**: [Your Name]
**Project Start**: January 2025
**Status**: Architecture Design Phase
