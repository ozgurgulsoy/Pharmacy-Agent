#!/usr/bin/env python3
"""
Quick configuration checker for Pharmacy Agent.
Shows current settings and performance configuration.
"""

import os
import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent))

try:
    from src.config import settings
    
    print("\n" + "="*70)
    print(" üîß PHARMACY AGENT - CURRENT CONFIGURATION")
    print("="*70)
    
    print("\nüìå API CONFIGURATION")
    print("-" * 70)
    api_key = settings.OPENAI_API_KEY
    if api_key:
        masked_key = api_key[:8] + "..." + api_key[-4:] if len(api_key) > 12 else "***"
        print(f"  OpenAI API Key:        {masked_key} ‚úì")
    else:
        print(f"  OpenAI API Key:        ‚ùå NOT SET")
    
    print("\nü§ñ MODEL CONFIGURATION")
    print("-" * 70)
    print(f"  LLM Model:             {settings.LLM_MODEL}")
    print(f"  Embedding Model:       {settings.EMBEDDING_MODEL}")
    print(f"  Max Tokens:            {settings.MAX_TOKENS}")
    print(f"  Temperature:           {settings.TEMPERATURE}")
    
    print("\nüìä RETRIEVAL SETTINGS")
    print("-" * 70)
    print(f"  Chunking Strategy:     {settings.CHUNKING_STRATEGY}")
    print(f"  Chunk Size:            {settings.CHUNK_SIZE} chars")
    print(f"  Chunk Overlap:         {settings.CHUNK_OVERLAP} chars")
    print(f"  Top K Chunks:          {settings.TOP_K_CHUNKS}")
    
    print("\n‚ö° PERFORMANCE FEATURES")
    print("-" * 70)
    print(f"  Streaming:             {'‚úì Enabled' if settings.ENABLE_STREAMING else '‚úó Disabled'}")
    print(f"  Parallel Embeddings:   {'‚úì Enabled' if settings.PARALLEL_EMBEDDINGS else '‚úó Disabled'}")
    print(f"  Cache Embeddings:      {'‚úì Enabled' if settings.CACHE_EMBEDDINGS else '‚úó Disabled'}")
    
    print("\nüìÅ FILE PATHS")
    print("-" * 70)
    print(f"  FAISS Index:           {settings.FAISS_INDEX_PATH}")
    faiss_exists = os.path.exists(settings.FAISS_INDEX_PATH)
    print(f"                         {'‚úì Exists' if faiss_exists else '‚ùå NOT FOUND'}")
    
    print(f"  FAISS Metadata:        {settings.FAISS_METADATA_PATH}")
    metadata_exists = os.path.exists(settings.FAISS_METADATA_PATH)
    print(f"                         {'‚úì Exists' if metadata_exists else '‚ùå NOT FOUND'}")
    
    print(f"  SUT PDF:               {settings.SUT_PDF_PATH}")
    pdf_exists = os.path.exists(settings.SUT_PDF_PATH)
    print(f"                         {'‚úì Exists' if pdf_exists else '‚ùå NOT FOUND'}")
    
    print("\nüåç LANGUAGE & OUTPUT")
    print("-" * 70)
    print(f"  Output Language:       {settings.OUTPUT_LANGUAGE}")
    
    # Performance assessment
    print("\nüìà PERFORMANCE ASSESSMENT")
    print("-" * 70)
    
    # Model assessment
    if settings.LLM_MODEL in ["gpt-4o-mini", "gpt-3.5-turbo-0125"]:
        print("  ‚úÖ Using fast model")
    elif "gpt-4" in settings.LLM_MODEL:
        print("  ‚ö†Ô∏è  Using slow model (gpt-4) - consider gpt-4o-mini")
    else:
        print(f"  ‚ÑπÔ∏è  Using: {settings.LLM_MODEL}")
    
    # Chunk assessment
    if settings.TOP_K_CHUNKS <= 3:
        print("  ‚ö° Fast retrieval (3 chunks) - may miss context")
    elif settings.TOP_K_CHUNKS <= 5:
        print("  ‚úÖ Balanced retrieval (5 chunks)")
    else:
        print("  üéØ Thorough retrieval (10+ chunks) - slower but comprehensive")
    
    # Cache assessment
    if settings.CACHE_EMBEDDINGS:
        cache_dir = Path("data/embedding_cache")
        if cache_dir.exists():
            cache_files = list(cache_dir.glob("*.pkl"))
            print(f"  ‚úÖ Embedding cache active ({len(cache_files)} cached queries)")
        else:
            print("  ‚ö†Ô∏è  Embedding cache enabled but no cache files yet")
    else:
        print("  ‚ùå Embedding cache disabled - queries will be slower")
    
    # Overall recommendation
    print("\nüí° RECOMMENDATION")
    print("-" * 70)
    
    if not api_key:
        print("  ‚ùå Set OPENAI_API_KEY in .env file")
    elif not faiss_exists:
        print("  ‚ùå Run: python scripts/setup_faiss.py")
    elif settings.LLM_MODEL == "gpt-4o-mini" and settings.TOP_K_CHUNKS == 5:
        print("  ‚úÖ Configuration is optimal!")
    elif "gpt-4" in settings.LLM_MODEL and "mini" not in settings.LLM_MODEL:
        print("  ‚ö†Ô∏è  Consider using gpt-4o-mini for faster responses")
    else:
        print("  ‚úÖ Configuration looks good!")
    
    print("\nüöÄ NEXT STEPS")
    print("-" * 70)
    print("  1. Test performance:   python benchmark_performance.py")
    print("  2. Start server:       python run.py")
    print("  3. Read guide:         cat PERFORMANCE_GUIDE.md")
    print("="*70)
    print()
    
except ImportError as e:
    print(f"\n‚ùå Error importing settings: {e}")
    print("\nMake sure you're in the project root directory.")
    sys.exit(1)
except Exception as e:
    print(f"\n‚ùå Error: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)
